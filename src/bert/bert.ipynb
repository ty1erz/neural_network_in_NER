{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-01T21:55:27.549293Z","iopub.execute_input":"2023-05-01T21:55:27.549563Z","iopub.status.idle":"2023-05-01T21:55:27.572135Z","shell.execute_reply.started":"2023-05-01T21:55:27.549538Z","shell.execute_reply":"2023-05-01T21:55:27.571086Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/ner-data/ner.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/ner-data/ner.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:36:43.314589Z","iopub.execute_input":"2023-05-01T22:36:43.314940Z","iopub.status.idle":"2023-05-01T22:36:43.463588Z","shell.execute_reply.started":"2023-05-01T22:36:43.314911Z","shell.execute_reply":"2023-05-01T22:36:43.462644Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"                                                    text  \\\n0      Thousands of demonstrators have marched throug...   \n1      Iranian officials say they expect to get acces...   \n2      Helicopter gunships Saturday pounded militant ...   \n3      They left after a tense hour-long standoff wit...   \n4      U.N. relief coordinator Jan Egeland said Sunda...   \n...                                                  ...   \n47954  Opposition leader Mir Hossein Mousavi has said...   \n47955  On Thursday , Iranian state media published a ...   \n47956  Following Iran 's disputed June 12 elections ,...   \n47957  Since then , authorities have held public tria...   \n47958  The United Nations is praising the use of mili...   \n\n                                                  labels  \n0      O O O O O O B-geo O O O O O B-geo O O O O O B-...  \n1      B-gpe O O O O O O O O O O O O O O B-tim O O O ...  \n2      O O B-tim O O O O O B-geo O O O O O B-org O O ...  \n3                                  O O O O O O O O O O O  \n4      B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...  \n...                                                  ...  \n47954  O O O B-per I-per O O O O O O O O O O O O O O ...  \n47955  O B-tim O B-gpe O O O O O O O O B-org I-org O ...  \n47956  O B-geo O O B-tim I-tim O O O O O O O O O O O ...  \n47957          O O O O O O O O O O O O O O O O O O O O O  \n47958  O B-org I-org O O O O O O O O O O O O O O B-ti...  \n\n[47959 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Thousands of demonstrators have marched throug...</td>\n      <td>O O O O O O B-geo O O O O O B-geo O O O O O B-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Iranian officials say they expect to get acces...</td>\n      <td>B-gpe O O O O O O O O O O O O O O B-tim O O O ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Helicopter gunships Saturday pounded militant ...</td>\n      <td>O O B-tim O O O O O B-geo O O O O O B-org O O ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>They left after a tense hour-long standoff wit...</td>\n      <td>O O O O O O O O O O O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>U.N. relief coordinator Jan Egeland said Sunda...</td>\n      <td>B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47954</th>\n      <td>Opposition leader Mir Hossein Mousavi has said...</td>\n      <td>O O O B-per I-per O O O O O O O O O O O O O O ...</td>\n    </tr>\n    <tr>\n      <th>47955</th>\n      <td>On Thursday , Iranian state media published a ...</td>\n      <td>O B-tim O B-gpe O O O O O O O O B-org I-org O ...</td>\n    </tr>\n    <tr>\n      <th>47956</th>\n      <td>Following Iran 's disputed June 12 elections ,...</td>\n      <td>O B-geo O O B-tim I-tim O O O O O O O O O O O ...</td>\n    </tr>\n    <tr>\n      <th>47957</th>\n      <td>Since then , authorities have held public tria...</td>\n      <td>O O O O O O O O O O O O O O O O O O O O O</td>\n    </tr>\n    <tr>\n      <th>47958</th>\n      <td>The United Nations is praising the use of mili...</td>\n      <td>O B-org I-org O O O O O O O O O O O O O O B-ti...</td>\n    </tr>\n  </tbody>\n</table>\n<p>47959 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\n# Split labels based on whitespace and turn them into a list\nlabels = [i.split() for i in df['labels'].values.tolist()]\n\n# Check how many labels are there in the dataset\nunique_labels = set()\n\nfor lb in labels:\n  [unique_labels.add(i) for i in lb if i not in unique_labels]\n \n\n# Map each label into its id representation and vice versa\nlabels_to_ids = {k: v for v, k in enumerate(sorted(unique_labels))}\nids_to_labels = {v: k for v, k in enumerate(sorted(unique_labels))}","metadata":{"execution":{"iopub.status.busy":"2023-05-01T21:55:41.610852Z","iopub.execute_input":"2023-05-01T21:55:41.611184Z","iopub.status.idle":"2023-05-01T21:55:41.835169Z","shell.execute_reply.started":"2023-05-01T21:55:41.611157Z","shell.execute_reply":"2023-05-01T21:55:41.834194Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizerFast\n\ntokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')","metadata":{"execution":{"iopub.status.busy":"2023-05-01T21:55:41.837138Z","iopub.execute_input":"2023-05-01T21:55:41.837460Z","iopub.status.idle":"2023-05-01T21:55:46.761724Z","shell.execute_reply.started":"2023-05-01T21:55:41.837430Z","shell.execute_reply":"2023-05-01T21:55:46.760886Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7016d58ed50c4706b0a8893bf783c92f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba94292c350b4c2fa888f07331c2bade"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e01f2a75a494556b48409cf871e3392"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d40fd285d8f4708aee63c579e25dbd9"}},"metadata":{}}]},{"cell_type":"code","source":"\nimport torch\n\ndef align_label(texts, labels):\n    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n\n    word_ids = tokenized_inputs.word_ids()\n\n    previous_word_idx = None\n    label_ids = []\n\n    for word_idx in word_ids:\n\n        if word_idx is None:\n            label_ids.append(-100)\n\n        elif word_idx != previous_word_idx:\n            try:\n                label_ids.append(labels_to_ids[labels[word_idx]])\n            except:\n                label_ids.append(-100)\n        else:\n            try:\n                label_ids.append(labels_to_ids[labels[word_idx]] if label_all_tokens else -100)\n            except:\n                label_ids.append(-100)\n        previous_word_idx = word_idx\n\n    return label_ids\n\nclass DataSequence(torch.utils.data.Dataset):\n\n    def __init__(self, df):\n\n        lb = [i.split() for i in df['labels'].values.tolist()]\n        txt = df['text'].values.tolist()\n        self.texts = [tokenizer(str(i),\n                               padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\") for i in txt]\n        self.labels = [align_label(i,j) for i,j in zip(txt, lb)]\n\n    def __len__(self):\n\n        return len(self.labels)\n\n    def get_batch_data(self, idx):\n\n        return self.texts[idx]\n\n    def get_batch_labels(self, idx):\n\n        return torch.LongTensor(self.labels[idx])\n\n    def __getitem__(self, idx):\n\n        batch_data = self.get_batch_data(idx)\n        batch_labels = self.get_batch_labels(idx)\n\n        return batch_data, batch_labels\n        ","metadata":{"execution":{"iopub.status.busy":"2023-05-01T21:55:46.763242Z","iopub.execute_input":"2023-05-01T21:55:46.763827Z","iopub.status.idle":"2023-05-01T21:55:51.790960Z","shell.execute_reply.started":"2023-05-01T21:55:46.763792Z","shell.execute_reply":"2023-05-01T21:55:51.790085Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ndf = df.iloc[:10000]\ndf_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n                            [int(.8 * len(df)), int(.9 * len(df))])","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:36:49.900218Z","iopub.execute_input":"2023-05-01T22:36:49.900588Z","iopub.status.idle":"2023-05-01T22:36:49.910139Z","shell.execute_reply.started":"2023-05-01T22:36:49.900560Z","shell.execute_reply":"2023-05-01T22:36:49.909225Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:36:51.276184Z","iopub.execute_input":"2023-05-01T22:36:51.276528Z","iopub.status.idle":"2023-05-01T22:36:51.287260Z","shell.execute_reply.started":"2023-05-01T22:36:51.276500Z","shell.execute_reply":"2023-05-01T22:36:51.286354Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"                                                   text  \\\n0     Thousands of demonstrators have marched throug...   \n1     Iranian officials say they expect to get acces...   \n2     Helicopter gunships Saturday pounded militant ...   \n3     They left after a tense hour-long standoff wit...   \n4     U.N. relief coordinator Jan Egeland said Sunda...   \n...                                                 ...   \n9995  Government and African Union troops captured t...   \n9996  The militants were trying to take it back , bu...   \n9997  Somalia has experienced nearly two decades of ...   \n9998  The current government has been wracked by inf...   \n9999  The British and Irish prime ministers say much...   \n\n                                                 labels  \n0     O O O O O O B-geo O O O O O B-geo O O O O O B-...  \n1     B-gpe O O O O O O O O O O O O O O B-tim O O O ...  \n2     O O B-tim O O O O O B-geo O O O O O B-org O O ...  \n3                                 O O O O O O O O O O O  \n4     B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...  \n...                                                 ...  \n9995                O O B-geo I-geo O O O O O O O O O O  \n9996        O O O O O O O O O O O O O B-tim O O O O O O  \n9997        B-geo O O O O O O O O O O O O O O O O O O O  \n9998    O O O O O O O O O O O O O O O O O O O B-org O O  \n9999  O B-gpe O B-gpe O O O O O O O O O B-geo I-geo ...  \n\n[10000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Thousands of demonstrators have marched throug...</td>\n      <td>O O O O O O B-geo O O O O O B-geo O O O O O B-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Iranian officials say they expect to get acces...</td>\n      <td>B-gpe O O O O O O O O O O O O O O B-tim O O O ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Helicopter gunships Saturday pounded militant ...</td>\n      <td>O O B-tim O O O O O B-geo O O O O O B-org O O ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>They left after a tense hour-long standoff wit...</td>\n      <td>O O O O O O O O O O O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>U.N. relief coordinator Jan Egeland said Sunda...</td>\n      <td>B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>Government and African Union troops captured t...</td>\n      <td>O O B-geo I-geo O O O O O O O O O O</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>The militants were trying to take it back , bu...</td>\n      <td>O O O O O O O O O O O O O B-tim O O O O O O</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>Somalia has experienced nearly two decades of ...</td>\n      <td>B-geo O O O O O O O O O O O O O O O O O O O</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>The current government has been wracked by inf...</td>\n      <td>O O O O O O O O O O O O O O O O O O O B-org O O</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>The British and Irish prime ministers say much...</td>\n      <td>O B-gpe O B-gpe O O O O O O O O O B-geo I-geo ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import BertForTokenClassification\n\nclass BertModel(torch.nn.Module):\n\n    def __init__(self):\n\n        super(BertModel, self).__init__()\n\n        self.bert = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(unique_labels))\n\n    def forward(self, input_id, mask, label):\n\n        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n\n        return output\n\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-05-01T21:59:37.185768Z","iopub.execute_input":"2023-05-01T21:59:37.186125Z","iopub.status.idle":"2023-05-01T21:59:37.193840Z","shell.execute_reply.started":"2023-05-01T21:59:37.186098Z","shell.execute_reply":"2023-05-01T21:59:37.192662Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-05-01T21:59:38.797827Z","iopub.execute_input":"2023-05-01T21:59:38.798167Z","iopub.status.idle":"2023-05-01T21:59:38.804604Z","shell.execute_reply.started":"2023-05-01T21:59:38.798141Z","shell.execute_reply":"2023-05-01T21:59:38.803465Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\ndef train_loop(model, df_train, df_val):\n\n    train_dataset = DataSequence(df_train)\n    val_dataset = DataSequence(df_val)\n\n    train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=BATCH_SIZE, shuffle=True)\n    val_dataloader = DataLoader(val_dataset, num_workers=4, batch_size=BATCH_SIZE)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n\n    if use_cuda:\n        model = model.cuda()\n\n    best_acc = 0\n    best_loss = 1000\n\n    for epoch_num in range(EPOCHS):\n\n        total_acc_train = 0\n        total_loss_train = 0\n\n        model.train()\n\n        for train_data, train_label in tqdm(train_dataloader):\n\n            train_label = train_label.to(device)\n            mask = train_data['attention_mask'].squeeze(1).to(device)\n            input_id = train_data['input_ids'].squeeze(1).to(device)\n\n            optimizer.zero_grad()\n            loss, logits = model(input_id, mask, train_label)\n\n            for i in range(logits.shape[0]):\n\n              logits_clean = logits[i][train_label[i] != -100]\n              label_clean = train_label[i][train_label[i] != -100]\n\n              predictions = logits_clean.argmax(dim=1)\n              acc = (predictions == label_clean).float().mean()\n              total_acc_train += acc\n              total_loss_train += loss.item()\n\n            loss.backward()\n            optimizer.step()\n\n        model.eval()\n\n        total_acc_val = 0\n        total_loss_val = 0\n\n        for val_data, val_label in val_dataloader:\n\n            val_label = val_label.to(device)\n            mask = val_data['attention_mask'].squeeze(1).to(device)\n            input_id = val_data['input_ids'].squeeze(1).to(device)\n\n            loss, logits = model(input_id, mask, val_label)\n\n            for i in range(logits.shape[0]):\n\n              logits_clean = logits[i][val_label[i] != -100]\n              label_clean = val_label[i][val_label[i] != -100]\n\n              predictions = logits_clean.argmax(dim=1)\n              acc = (predictions == label_clean).float().mean()\n              total_acc_val += acc\n              total_loss_val += loss.item()\n\n        val_accuracy = total_acc_val / len(df_val)\n        val_loss = total_loss_val / len(df_val)\n\n        print(\n            f'Epochs: {epoch_num + 1} | Loss: {total_loss_train / len(df_train): .3f} | Accuracy: {total_acc_train / len(df_train): .3f} | Val_Loss: {total_loss_val / len(df_val): .3f} | Accuracy: {total_acc_val / len(df_val): .3f}')\n\nLEARNING_RATE = 5e-3\nEPOCHS = 2\nBATCH_SIZE = 2\n\nmodel = BertModel()\ntrain_loop(model, df_train, df_val)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:36:59.461389Z","iopub.execute_input":"2023-05-01T22:36:59.463970Z","iopub.status.idle":"2023-05-01T23:03:19.821949Z","shell.execute_reply.started":"2023-05-01T22:36:59.463937Z","shell.execute_reply":"2023-05-01T23:03:19.820691Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n  0%|          | 0/4000 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4000/4000 [12:28<00:00,  5.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 1 | Loss:  0.372 | Accuracy:  0.898 | Val_Loss:  0.228 | Accuracy:  0.932\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/4000 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4000/4000 [12:29<00:00,  5.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpochs: 2 | Loss:  0.231 | Accuracy:  0.931 | Val_Loss:  0.186 | Accuracy:  0.943\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install seqeval","metadata":{"execution":{"iopub.status.busy":"2023-05-01T22:32:06.988385Z","iopub.execute_input":"2023-05-01T22:32:06.988761Z","iopub.status.idle":"2023-05-01T22:32:18.135903Z","shell.execute_reply.started":"2023-05-01T22:32:06.988713Z","shell.execute_reply":"2023-05-01T22:32:18.134713Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.23.5)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.9.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=8414d9d8c24cf8b54cfa1faa0617b9b51afae50913d29dfba61fd4a5d11c0b23\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from seqeval.metrics import classification_report\ndef evaluate(model, df_test):\n\n    test_dataset = DataSequence(df_test)\n\n    test_dataloader = DataLoader(test_dataset, num_workers=4, batch_size=1)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    if use_cuda:\n        model = model.cuda()\n\n    total_acc_test = 0.0\n    y_true=[]\n    y_pred=[]\n    for test_data, test_label in test_dataloader:\n\n            test_label = test_label.to(device)\n            mask = test_data['attention_mask'].squeeze(1).to(device)\n\n            input_id = test_data['input_ids'].squeeze(1).to(device)\n\n            loss, logits = model(input_id, mask, test_label)\n\n            for i in range(logits.shape[0]):\n\n                logits_clean = logits[i][test_label[i] != -100]\n                label_clean = test_label[i][test_label[i] != -100]\n                y_true += [np.array(label_clean.tolist())]\n                predictions = logits_clean.argmax(dim=1)\n                y_pred += [np.array(predictions.tolist())]\n                acc = (predictions == label_clean).float().mean()\n                total_acc_test += acc\n\n    val_accuracy = total_acc_test / len(df_test)\n    print(f'Test Accuracy: {total_acc_test / len(df_test): .3f}')\n    return np.array(y_true), np.array(y_pred)\n\n\ny_true, y_pred =evaluate(model, df_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T23:05:00.404561Z","iopub.execute_input":"2023-05-01T23:05:00.404975Z","iopub.status.idle":"2023-05-01T23:05:39.600391Z","shell.execute_reply.started":"2023-05-01T23:05:00.404939Z","shell.execute_reply":"2023-05-01T23:05:39.599234Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTest Accuracy:  0.941\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/3381990960.py:38: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  return np.array(y_true), np.array(y_pred)\n","output_type":"stream"}]},{"cell_type":"code","source":"true_label=[]\nfor i in y_true:\n    true=[]\n    for j in i:\n        true +=[ids_to_labels[j]]\n    true_label +=[true]","metadata":{"execution":{"iopub.status.busy":"2023-05-01T23:06:01.711537Z","iopub.execute_input":"2023-05-01T23:06:01.711948Z","iopub.status.idle":"2023-05-01T23:06:01.726715Z","shell.execute_reply.started":"2023-05-01T23:06:01.711916Z","shell.execute_reply":"2023-05-01T23:06:01.725651Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"pred_label=[]\nfor i in y_pred:\n    pred=[]\n    for j in i:\n        pred +=[ids_to_labels[j]]\n    pred_label +=[pred]","metadata":{"execution":{"iopub.status.busy":"2023-05-01T23:06:05.304287Z","iopub.execute_input":"2023-05-01T23:06:05.305414Z","iopub.status.idle":"2023-05-01T23:06:05.318741Z","shell.execute_reply.started":"2023-05-01T23:06:05.305374Z","shell.execute_reply":"2023-05-01T23:06:05.317893Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"print(classification_report(true_label, pred_label))","metadata":{"execution":{"iopub.status.busy":"2023-05-01T23:06:08.235607Z","iopub.execute_input":"2023-05-01T23:06:08.235969Z","iopub.status.idle":"2023-05-01T23:06:08.600818Z","shell.execute_reply.started":"2023-05-01T23:06:08.235940Z","shell.execute_reply":"2023-05-01T23:06:08.599803Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n         art       0.00      0.00      0.00         7\n         eve       0.00      0.00      0.00         6\n         geo       0.75      0.69      0.72       761\n         gpe       0.86      0.74      0.80       317\n         nat       0.00      0.00      0.00         3\n         org       0.50      0.42      0.46       411\n         per       0.59      0.59      0.59       363\n         tim       0.74      0.59      0.66       444\n\n   micro avg       0.69      0.61      0.65      2312\n   macro avg       0.43      0.38      0.40      2312\nweighted avg       0.69      0.61      0.65      2312\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}